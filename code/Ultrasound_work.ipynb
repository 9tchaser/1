{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "#定义超参数\n",
    "device = torch.device('cuda' if \n",
    "                      torch.cuda.is_available()\n",
    "                      else 'cpu')\n",
    "lr=0.0002\n",
    "batch_size = 128\n",
    "num_epoch = 50\n",
    "latent_size = 100\n",
    "image_size=28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 60\u001b[0m\n\u001b[0;32m     56\u001b[0m train_loader\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m     57\u001b[0m     train_dataset,batch_size\u001b[38;5;241m=\u001b[39mbatch_size,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset)):\n\u001b[1;32m---> 60\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 假设数据集返回的是图像数据和标签数据的元组\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     tensor_size \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize()  \u001b[38;5;66;03m# 获取图像数据的大小\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m type:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(train_dataset[i])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m )\n",
      "Cell \u001b[1;32mIn[135], line 35\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m label_tensor\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(label_dict\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m---> 35\u001b[0m tensor_data\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_data\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 调整图片大小?\n",
    "    transforms.ToTensor(),\n",
    "      transforms.Normalize((0.5,),(0.5,))  # 转换为Tensor\n",
    "])\n",
    "\n",
    "# 自定义Dataset类\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,folder_path,label_dict,transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.label_dict=label_dict\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(folder_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder_path, self.images[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        #label = self.label_dict[self.images[idx]]\n",
    "\n",
    "        \n",
    "        image = self.transform(image)#张量\n",
    "            \n",
    "        \t\t#####问题：怎么拼接\n",
    "        # 删除第一个维度\n",
    "        image = image.squeeze(0)\n",
    "\n",
    "\n",
    "        label_tensor=torch.tensor(list(label_dict.values()))\n",
    "        tensor_data=torch.cat((label_tensor.unsqueeze(0), image), dim=0)\n",
    "\n",
    "        return tensor_data\n",
    "\n",
    " # 从CSV文件中读取标签信息并转换为字典\n",
    "def labels_to_dict(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    label_dict = dict(zip(df['Image_filename'], df['Classification']))\n",
    "    return label_dict\n",
    "\n",
    "# 指定CSV文件路径\n",
    "csv_file = \"D:\\MONAI\\CGAN_Image_sup\\CGAN_Image\\data\\image_labels.csv\"\n",
    "\n",
    "# 将CSV文件中的标签信息转换为字典\n",
    "label_dict = labels_to_dict(csv_file)\n",
    "#print(label_dict) \n",
    "\n",
    "# 创建自定义Dataset实例\n",
    "train_dataset = CustomDataset(folder_path=\"D:\\MONAI\\CGAN_Image_sup\\CGAN_Image\\data/all_images\",\n",
    "                              label_dict=label_dict,transform=transform)\n",
    "#train_dataset\n",
    "train_loader= torch.utils.data.DataLoader(\n",
    "    train_dataset,batch_size=batch_size,shuffle=True\n",
    ")\n",
    "for i in range(len(train_dataset)):\n",
    "    images, labels = train_dataset[i]  # 假设数据集返回的是图像数据和标签数据的元组\n",
    "    tensor_size = images.size()  # 获取图像数据的大小\n",
    "    print(f\"Data item {i+1} size: {tensor_size} type:{type(train_dataset[i])}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset)):\n\u001b[1;32m----> 2\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 假设数据集返回的是图像数据和标签数据的元组\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     tensor_size \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize()  \u001b[38;5;66;03m# 获取图像数据的大小\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m type:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(train_dataset[i])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m )\n",
      "Cell \u001b[1;32mIn[125], line 30\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\u001b[38;5;66;03m#张量\u001b[39;00m\n\u001b[0;32m     29\u001b[0m image\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m label_tensor\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m())\n\u001b[0;32m     31\u001b[0m tensor_data\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat((label_tensor, image), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_data\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    images, labels = train_dataset[i]  # 假设数据集返回的是图像数据和标签数据的元组\n",
    "    tensor_size = images.size()  # 获取图像数据的大小\n",
    "    print(f\"Data item {i+1} size: {tensor_size} type:{type(train_dataset[i])}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.label_emb=nn.Embedding(10,10)\n",
    "        self.fc1=nn.Linear(latent_size+10,256)\n",
    "        self.fc2=nn.Linear(256,512)\n",
    "        self.fc3=nn.Linear(512,image_size)\n",
    "    def forward(self,x,labels):\n",
    "        emb=self.label_emb(labels)\n",
    "        x=torch.cat([x,emb],1)\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=torch.relu(self.fc2(x))\n",
    "        x=torch.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.label_emb=nn.Embedding(10,10)\n",
    "        self.fc1=nn.Linear(image_size+10,512)\n",
    "        self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,1)\n",
    "    def forward(self,x,labels):\n",
    "        emb=self.label_emb(labels)\n",
    "        x=torch.cat([x,emb],1)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=torch.relu(self.fc2(x))\n",
    "        x=torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络初始化\n",
    "generator=Generator().to(device)\n",
    "discriminator=Discriminator().to(device)\n",
    "#定义损失函数\n",
    "loss= nn.BCELoss()\n",
    "g_optimizer=optim.Adam(generator.parameters(),lr=lr)\n",
    "d_optimizer=optim.Adam(discriminator.parameters(),lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#训练\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,(images,labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m      4\u001b[0m         train_loader):\n\u001b[0;32m      5\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m         real_images\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mview(batch_size,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "for epoch in range(num_epoch):\n",
    "    for i,(images,labels) in enumerate(\n",
    "        train_loader):\n",
    "        batch_size=images.shape[0]\n",
    "        real_images=images.view(batch_size,-1).to(device)\n",
    "        real_labels=labels.to(device)\n",
    "        #判别器计算真实图像误差\n",
    "        real_pred=discriminator(real_images,real_labels)\n",
    "        d_loss_real=loss(real_pred,\n",
    "                         torch.ones(batch_size,1).to(device))\n",
    "        #判别器计算虚假图像误差\n",
    "        noise=torch.randn(batch_size,latent_size).to(device)\n",
    "        fake_images=generator(noise,labels.to(device))\n",
    "        fake_pred=discriminator(fake_images,labels.to(device))\n",
    "        d_loss_fake=loss(fake_pred,\n",
    "                         torch.zeros(batch_size,1).to(device))\n",
    "        \n",
    "        d_loss=d_loss_fake+d_loss_real\n",
    "        #更新判别器参数\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        noise=torch.randn(batch_size,latent_size).to(device)\n",
    "        fake_images=generator(noise,labels.to(device))\n",
    "        pred=discriminator(fake_images,labels.to(device))\n",
    "        g_loss=loss(pred,\n",
    "                    torch.ones(batch_size,1).to(device)) \n",
    "        #更新生成器参数\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if i%100==0:\n",
    "            print('Epoch [{}/{}], Step[{}/{}],d_loss:{:.4f},g_loss:{:.4f}'\n",
    "                  .format(epoch+1,num_epoch,i+1,len(train_loader),d_loss.item(),g_loss.item()))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
